/**
 * Governance Utility
 * Enforces compliance and safety standards for user-generated content.
 */

const UNSAFE_PATTERNS = [
    /kill/i,
    /bomb/i,
    /sue you/i,
    /lawsuit/i, // Context dependent, but flagged for review in automated systems usually
    /fuck/i,
    /shit/i,
    /asshole/i,
    /bitch/i,
    /threaten/i
];

const WARNING_PATTERNS = [
    /harass/i,
    /stupid/i,
    /incompetent/i
];

export interface ValidationResult {
    isValid: boolean;
    error?: string;
    warning?: string;
}

export function validateDisputeContent(content: string): ValidationResult {
    if (!content) return { isValid: true };

    // Check for hard blocks (Threats/Profanity)
    for (const pattern of UNSAFE_PATTERNS) {
        if (pattern.test(content)) {
            return {
                isValid: false,
                error: "Content contains unsafe or threatening language. Please maintain a professional tone."
            };
        }
    }

    // Check for warnings (Aggressive tone)
    for (const pattern of WARNING_PATTERNS) {
        if (pattern.test(content)) {
            return {
                isValid: true,
                warning: "Warning: Aggressive language detected. This may hurt your credibility."
            };
        }
    }

    return { isValid: true };
}

export function generateAuditFooter(): string {
    const date = new Date().toISOString();
    const session = crypto.randomUUID().slice(0, 8);
    return `Generated by Credit Uâ„¢ Secure Lab | ${date} | Session: ${session}`;
}
